{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\LeHoa\\Anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9bb74cbb55b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' Error loading \"{}\" or one of its dependencies.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdll\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\LeHoa\\Anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import config\n",
    "from preprocess import read_data, MyDataset\n",
    "from model import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Extractor:\n",
    "    def __init__(self):\n",
    "        sample_rate = 16000\n",
    "        self.mfcc = MFCC(sample_rate=sample_rate, n_mfcc=40,\n",
    "                         melkwargs={'win_length': int(0.025 * sample_rate),\n",
    "                                    'hop_length': int(0.010 * sample_rate),\n",
    "                                    'n_fft': int(0.025 * sample_rate)})\n",
    "\n",
    "    def extract_feature(self, audio):\n",
    "        shape = audio.size()\n",
    "        audio = audio.reshape(-1, shape[-1])\n",
    "        feature = self.mfcc(audio)\n",
    "        feature = feature.reshape(shape[:-1] + feature.shape[-2:])[:, 0]\n",
    "        feature = feature.transpose(1, 2)\n",
    "        return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir):\n",
    "    extractor = Extractor()\n",
    "    audio_dir = os.path.join(data_dir, \"audio\")\n",
    "    label_dir = os.path.join(data_dir, \"label\")\n",
    "    audio_silent = []\n",
    "    audio_cough = []\n",
    "\n",
    "    for filename in os.listdir(audio_dir):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename.replace(\".wav\", \".txt\"))\n",
    "        audio, sr = torchaudio.load(audio_path)\n",
    "        audio_size = audio.shape[1]\n",
    "        segment_silent = []\n",
    "        segment_cough = []\n",
    "\n",
    "        last = 0\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                start, end, _ = line.split()\n",
    "                start, end = int(float(start) * 16000), int(float(end) * 16000)\n",
    "                segment_silent.append((max(0, last), min(start, audio_size)))\n",
    "                segment_cough.append((max(0, start), min(end, audio_size)))\n",
    "                last = end\n",
    "\n",
    "            segment_silent.append((max(last, 0), audio_size))\n",
    "\n",
    "        for start, end in segment_silent:\n",
    "            chunk_sample = config.CHUNK * 16000 // 1000\n",
    "            if end - start >= chunk_sample:\n",
    "                if config.model == \"LSTM\":\n",
    "                    for x in range(start, end - chunk_sample, 160):\n",
    "                        audio_silent.append(audio[:, x: x + chunk_sample])\n",
    "                else:\n",
    "                    for i in range((end - chunk_sample - start) // chunk_sample):\n",
    "                        x = random.randint(start, end - chunk_sample)\n",
    "                        audio_silent.append(audio[:, x: x + chunk_sample])\n",
    "\n",
    "        for start, end in segment_cough:\n",
    "            chunk_sample = config.CHUNK * 16000 // 1000\n",
    "            if end - start >= chunk_sample:\n",
    "                if config.model == \"LSTM\":\n",
    "                    for x in range(start, end - chunk_sample, 160):\n",
    "                        audio_cough.append(audio[:, x: x + chunk_sample])\n",
    "                else:\n",
    "                    for i in range((end - chunk_sample - start) // chunk_sample):\n",
    "                        x = random.randint(start, end - chunk_sample)\n",
    "                        audio_cough.append(audio[:, x: x + chunk_sample])\n",
    "\n",
    "    audio_silent = torch.stack(audio_silent, dim=0)\n",
    "    audio_cough = torch.stack(audio_cough, dim=0)\n",
    "    feature_silent = extractor.extract_feature(audio_silent)\n",
    "    feature_cough = extractor.extract_feature(audio_cough)\n",
    "    feature = torch.cat([feature_silent, feature_cough], dim=0)\n",
    "    label = torch.tensor(([0] * feature_silent.shape[0] + [1] * feature_cough.shape[0]), dtype=torch.int64)\n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm():\n",
    "    feature, label = read_data(config.DATA_DIR)\n",
    "    train_feature, test_feature, train_label, test_label = train_test_split(feature, label)\n",
    "    train_feature = train_feature.reshape(train_feature.shape[0], -1)\n",
    "    test_feature = test_feature.reshape(test_feature.shape[0], -1)\n",
    "    svm = SVC()\n",
    "    svm.fit(train_feature.numpy(), train_label.numpy())\n",
    "    y_pred = svm.predict(test_feature.numpy())\n",
    "    pickle.dump(svm, open(\"resource/gmm.pkl\", 'wb'))\n",
    "    print(accuracy_score(test_label.numpy(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmm():\n",
    "    feature, label = read_data(config.DATA_DIR)\n",
    "    feature, label = feature.reshape(feature.shape[0], -1).numpy(), label.numpy()\n",
    "    train_feature, test_feature, train_label, test_label = train_test_split(feature, label)\n",
    "    model_0 = GaussianMixture(n_components=2, max_iter=100)\n",
    "    model_1 = GaussianMixture(n_components=2, max_iter=100)\n",
    "  \n",
    "    model_0.fit(train_feature[train_label == 0], train_label[train_label == 0])\n",
    "    model_1.fit(train_feature[train_label == 1], train_label[train_label == 1])\n",
    " \n",
    "    y_pred = []\n",
    "    score_0 = model_0.score_samples(test_feature)\n",
    "    score_1 = model_1.score_samples(test_feature)\n",
    "    for i in range(len(score_1)):\n",
    "        if score_0[i] > score_1[i]:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "\n",
    "    # print(model_0.score_samples(test_feature), model_1.score_samples(test_feature))\n",
    "    print(accuracy_score(test_label, y_pred))\n",
    "    pickle.dump(model_0, open(\"resource/non_cough.pkl\", 'wb'))\n",
    "    pickle.dump(model_1, open(\"resource/cough.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_value(indir, outdir, label_dir):\n",
    "    for filename in os.listdir(indir):\n",
    "        v = random.uniform(0.6, 1.5)\n",
    "        filleout = \"{}_value-{}.wav\".format(filename.replace(\".wav\", \"\"), str(v).replace(\".\", \"_\"))\n",
    "        inpath = os.path.join(indir, filename)\n",
    "        outpath = os.path.join(outdir, filleout)\n",
    "        inlabelpath = os.path.join(label_dir, filename.replace(\".wav\", \".txt\"))\n",
    "        outlabelpath = os.path.join(outdir, filleout.replace(\".wav\", \".txt\"))\n",
    "        os.system(\"sox -v {} {} {}\".format(v, inpath, outpath))\n",
    "        os.system(\"cp {} {}\".format(inlabelpath, outlabelpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_speed(indir, outdir, label_dir):\n",
    "    for filename in os.listdir(indir):\n",
    "        s = random.uniform(0.7, 1.4)\n",
    "        filleout = \"{}_speed-{}.wav\".format(filename.replace(\".wav\", \"\"), str(s).replace(\".\", \"_\"))\n",
    "        inpath = os.path.join(indir, filename)\n",
    "        outpath = os.path.join(outdir, filleout)\n",
    "        inlabelpath = os.path.join(label_dir, filename.replace(\".wav\", \".txt\"))\n",
    "        outlabelpath = os.path.join(outdir, filleout.replace(\".wav\", \".txt\"))\n",
    "        os.system(\"sox {} {} tempo {}\".format(inpath, outpath, s))\n",
    "\n",
    "\n",
    "        fw = open(outlabelpath, \"w\")\n",
    "        with open(inlabelpath, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                start, end, label = line.split()\n",
    "                start, end = float(start) / s, float(end) / s\n",
    "                write(\"{}\\t{}\\t{}\\n\".format(start, end, label))\n",
    "\n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir):\n",
    "    audio_dir = os.path.join(data_dir, \"audio\")\n",
    "    label_dir = os.path.join(data_dir, \"label\")\n",
    "    feature_silent = []\n",
    "    feature_cough = []\n",
    "\n",
    "    for filename in os.listdir(audio_dir):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename.replace(\".wav\", \".txt\"))\n",
    "        # audio, sr = torchaudio.load(audio_path)\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        mfcc_feature = librosa.feature.mfcc(y=audio, sr=sr, hop_length=int(0.010*sr), n_fft=int(0.025*sr), n_mfcc=40)\n",
    "        zcr_feature = librosa.feature.zero_crossing_rate(y=audio, hop_length=int(0.010 * sr))\n",
    "        feature = np.concatenate((mfcc_feature, zcr_feature)).transpose((1, 0))\n",
    "        # print(mfcc_feature.shape, zcr_feature.shape)\n",
    "\n",
    "        audio_size = feature.shape[0]\n",
    "        segment_silent = []\n",
    "        segment_cough = []\n",
    "\n",
    "        last = 0\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                start, end, _ = line.split()\n",
    "                start, end = int(float(start) * 1000) // 10, int(float(end) * 1000) // 10\n",
    "                # print(start, end, feature.shape)\n",
    "                segment_silent.append((max(0, last), min(start, audio_size)))\n",
    "                segment_cough.append((max(0, start), min(end, audio_size)))\n",
    "                last = end\n",
    "\n",
    "            segment_silent.append((max(last, 0), audio_size))\n",
    "\n",
    "        for start, end in segment_silent:\n",
    "            chunk_sample = config.CHUNK // 10\n",
    "            if end - start >= chunk_sample:\n",
    "                if config.model == \"LSTM\":\n",
    "                    for x in range(start, end - chunk_sample, 1):\n",
    "                        feature_silent.append(audio[:, x: x + chunk_sample])\n",
    "                else:\n",
    "                    if \"speed\" in filename or \"value\" in filename:\n",
    "                        continue\n",
    "\n",
    "                    for i in range((end - start) // chunk_sample):\n",
    "                        x = random.randint(start, end - chunk_sample)\n",
    "                        feature_silent.append(feature[x: x + chunk_sample])\n",
    "\n",
    "        for start, end in segment_cough:\n",
    "            chunk_sample = config.CHUNK // 10\n",
    "            if end - start >= chunk_sample:\n",
    "                if config.model == \"LSTM\":\n",
    "                    for x in range(start, end - chunk_sample, 1):\n",
    "                        feature_cough.append(audio[:, x: x + chunk_sample])\n",
    "                else:\n",
    "                    if \"speed\" in filename or \"value\" in filename:\n",
    "                        continue\n",
    "\n",
    "                    for i in range((end - start) // chunk_sample):\n",
    "                        x = random.randint(start, end - chunk_sample)\n",
    "                        feature_cough.append(feature[x: x + chunk_sample])\n",
    "\n",
    "    feature_silent = np.stack(feature_silent, axis=0)\n",
    "    feature_cough = np.stack(feature_cough, axis=0)\n",
    "\n",
    "    feature = np.concatenate([feature_silent, feature_cough], axis=0)\n",
    "    label = torch.tensor(([0] * feature_silent.shape[0] + [1] * feature_cough.shape[0]), dtype=torch.int64)\n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmm():\n",
    "    feature, label = read_data(config.DATA_DIR)\n",
    "    feature, label = feature.reshape(feature.shape[0], -1).numpy(), label.numpy()\n",
    "    train_feature, test_feature, train_label, test_label = train_test_split(feature, label)\n",
    "    model_0 = GaussianMixture(n_components=3, max_iter=100, weights_init=[1/3, 1/3, 1/3], random_state=42)\n",
    "    model_1 = GaussianMixture(n_components=3, max_iter=100, weights_init=[1/3, 1/3, 1/3], random_state=42)\n",
    "    # model.means_init = numpy.array([train_feture[train_label == i].mean(axis=0)\n",
    "    #                                 for i in range(2)])\n",
    "\n",
    "    model_0.fit(train_feature[train_label == 0], train_label[train_label == 0])\n",
    "    model_1.fit(train_feature[train_label == 1], train_label[train_label == 1])\n",
    "    # pred = model.predict(test_feature)\n",
    "    # for feat in test_feature:\n",
    "    y_pred = []\n",
    "    score_0 = model_0.score_samples(test_feature)\n",
    "    score_1 = model_1.score_samples(test_feature)\n",
    "    for i in range(len(score_1)):\n",
    "        if score_0[i] > score_1[i]:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "\n",
    "    # print(model_0.score_samples(test_feature), model_1.score_samples(test_feature))\n",
    "    print(accuracy_score(test_label, y_pred))\n",
    "\n",
    "    # recall and precision\n",
    "    matrix = classification_report(test_label, y_pred)\n",
    "    print(\"Classification report: \\n\", matrix)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "    con_matrix = confusion_matrix(test_label, y_pred)\n",
    "    class_names = [\"Non_cough\", \"Cough\"]\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(con_matrix, classes=class_names,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(con_matrix, classes=class_names, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    pickle.dump(model_0, open(\"resource/non_cough.pkl\", 'wb'))\n",
    "    pickle.dump(model_1, open(\"resource/cough.pkl\", 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir):\n",
    "    audio_dir = os.path.join(data_dir, \"audio\")\n",
    "    label_dir = os.path.join(data_dir, \"label\")\n",
    "    feature_silent = []\n",
    "    feature_cough = []\n",
    "\n",
    "    for filename in os.listdir(audio_dir):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        label_path = os.path.join(label_dir, filename.replace(\".wav\", \".txt\"))\n",
    "        # audio, sr = torchaudio.load(audio_path)\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        gfcc_feature = gfcc(sig=audio, fs=sr, num_ceps=13)\n",
    "        feature_size = gfcc_feature.shape[0]\n",
    "        mfcc_feature = librosa.feature.mfcc(y=audio, sr=sr, hop_length=int(0.010 * sr), n_fft=int(0.025 * sr),\n",
    "                                            n_mfcc=40).transpose(1, 0)[: feature_size]\n",
    "\n",
    "        zcr_feature = librosa.feature.zero_crossing_rate(y=audio, hop_length=int(0.010 * sr)).transpose(1, 0)[\n",
    "                      : feature_size]\n",
    "\n",
    "        feature = np.concatenate((mfcc_feature, gfcc_feature, zcr_feature), axis=1)\n",
    "\n",
    "        segment_silent = []\n",
    "        segment_cough = []\n",
    "\n",
    "        last = 0\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                start, end, _ = line.split()\n",
    "                start, end = int(float(start) * 1000) // 10, int(float(end) * 1000) // 10\n",
    "                segment_silent.append((max(0, last), min(start, feature_size)))\n",
    "                segment_cough.append((max(0, start), min(end, feature_size)))\n",
    "                last = end\n",
    "\n",
    "            segment_silent.append((max(last, 0), feature_size))\n",
    "\n",
    "        for start, end in segment_silent:\n",
    "            chunk_sample = config.CHUNK // 10\n",
    "            if end - start >= chunk_sample:\n",
    "                for x in range(start, end - chunk_sample, chunk_sample):\n",
    "                    feature_silent.append(feature[x: x + chunk_sample])\n",
    "\n",
    "\n",
    "        for start, end in segment_cough:\n",
    "            chunk_sample = config.CHUNK // 10\n",
    "            if end - start >= chunk_sample:\n",
    "                for x in range(start, end - chunk_sample, chunk_sample):\n",
    "                    feature_cough.append(feature[x: x + chunk_sample])\n",
    "\n",
    "\n",
    "    feature_silent = np.stack(feature_silent, axis=0)\n",
    "    feature_cough = np.stack(feature_cough, axis=0)\n",
    "\n",
    "    feature = np.concatenate([feature_silent, feature_cough], axis=0)\n",
    "    label = torch.tensor(([0] * feature_silent.shape[0] + [1] * feature_cough.shape[0]), dtype=torch.int64)\n",
    "    return feature, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
